{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e26a3108-3953-4e45-af6e-e3e4e0921ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Cell\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from eval_helper import calculate_mAP\n",
    "from torchvision import models\n",
    "from torch.utils.data import random_split\n",
    "from cocodataset import Compose, ToTensor, CocoDataset\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eda30ca4-256a-4bca-90fc-254d3f02dc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, loader, device, epoch, lr_scheduler):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    all_losses = []\n",
    "    all_losses_dict = []\n",
    "    \n",
    "    for images, targets in tqdm(loader):\n",
    "        # Skip batches with None\n",
    "        if images is None or targets is None or any(img is None for img in images) or any(tar is None for tar in targets):\n",
    "            continue\n",
    "\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: torch.tensor(v).to(device) for k, v in t.items()} for t in targets]\n",
    "        \n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        loss_dict_append = {k: v.item() for k, v in loss_dict.items()}\n",
    "        loss_value = losses.item()\n",
    "        \n",
    "        all_losses.append(loss_value)\n",
    "        all_losses_dict.append(loss_dict_append)\n",
    "        \n",
    "        if not math.isfinite(loss_value):\n",
    "            print(f\"Loss is {loss_value}, stopping training\")\n",
    "            print(loss_dict)\n",
    "            sys.exit(1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step()\n",
    "        \n",
    "    all_losses_dict = pd.DataFrame(all_losses_dict)\n",
    "    print(\"Epoch {}, lr: {:.6f}, loss: {:.6f}, loss_classifier: {:.6f}, loss_box: {:.6f}, loss_rpn_box: {:.6f}, loss_object: {:.6f}\".format(\n",
    "        epoch, optimizer.param_groups[0]['lr'], np.mean(all_losses),\n",
    "        all_losses_dict['loss_classifier'].mean(),\n",
    "        all_losses_dict['loss_box_reg'].mean(),\n",
    "        all_losses_dict['loss_rpn_box_reg'].mean(),\n",
    "        all_losses_dict['loss_objectness'].mean()\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "630321c6-a7cd-4eb6-8afd-359b519b447b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(val_loader, model, device, label_threshold=0.8, iou_threshold=0.5):\n",
    "    device1 = torch.device('cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    det_boxes = []\n",
    "    det_labels = []\n",
    "    det_scores = []\n",
    "    true_boxes = []\n",
    "    true_labels = []\n",
    "    true_difficulties = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(val_loader):\n",
    "            if images is None or targets is None or any(img is None for img in images) or any(tar is None for tar in targets):\n",
    "                continue\n",
    "\n",
    "            images = list(image.to(device) for image in images)\n",
    "            predictions = model(images)\n",
    "            for i in range(len(predictions)):\n",
    "                pred = predictions[i]\n",
    "                det_boxes.append(pred['boxes'][pred['scores'] > label_threshold].to(device1))\n",
    "                det_labels.append(pred['labels'][pred['scores'] > label_threshold].to(device1))\n",
    "                det_scores.append(torch.tensor([sc for sc in pred['scores'].tolist() if sc > label_threshold], dtype=torch.float32).to(device1))\n",
    "                true_boxes.append(targets[i]['boxes'].to(device1))\n",
    "                true_labels.append(targets[i]['labels'].to(device1))\n",
    "                true_difficulties.append(torch.zeros(len(targets[i]['labels'])).to(device1))   \n",
    "        APs, mAP = calculate_mAP(det_boxes, det_labels, det_scores, true_boxes, true_labels, true_difficulties, device1, iou_threshold)\n",
    "    return APs, mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a308b7aa-3a23-4e5d-bc74-9d5b3dfe2ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    n_classes = 2\n",
    "    model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = models.detection.faster_rcnn.FastRCNNPredictor(in_features, n_classes)\n",
    "    return model\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "def get_data_loader(img_folder, ann_file, train_flag=True):\n",
    "    transforms = Compose([ToTensor()])\n",
    "    dataset = CocoDataset(img_folder, ann_file, transforms=transforms)\n",
    "    batch_size = 4\n",
    "    workers = 4\n",
    "    if not train_flag:\n",
    "        workers = 1 \n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=train_flag, num_workers=workers,\n",
    "                                                pin_memory=True, collate_fn=collate_fn)\n",
    "    return data_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaf8bd31-4f0a-4f0d-ba83-db1c7e279194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: python script_name.py <train_img_folder> <train_ann_file> <val_img_folder> <val_ann_file>\n"
     ]
    }
   ],
   "source": [
    "def main(train_img_folder, train_ann_file, val_img_folder, val_ann_file):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "\n",
    "    model = get_model()\n",
    "    train_loader = get_data_loader(train_img_folder, train_ann_file, train_flag=True)\n",
    "    val_loader = get_data_loader(val_img_folder, val_ann_file, train_flag=False)\n",
    "\n",
    "    print(\"Number of GPUs: \" + str(n_gpu))\n",
    "\n",
    "    train_losses = []\n",
    "    n_epochs = 3\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    scheduler = None\n",
    "    loss_list = []\n",
    "\n",
    "    for epoch in range(n_epochs + 1):\n",
    "        train_one_epoch(model, optimizer, train_loader, device, epoch, scheduler)\n",
    "        print(evaluate(val_loader, model, device))\n",
    "        model.eval()\n",
    "        torch.save(model.state_dict(), 'model_epoch' + str(epoch) + '.pth')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) != 5:\n",
    "        print(\"Usage: python script_name.py <train_img_folder> <train_ann_file> <val_img_folder> <val_ann_file>\")\n",
    "    else:\n",
    "        main(sys.argv[1], sys.argv[2], sys.argv[3], sys.argv[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a53e83-1225-4fdb-b7f6-71d86216ead2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/turtle/anaconda3/envs/project-oval/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/turtle/anaconda3/envs/project-oval/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.11s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Number of GPUs: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1026 [00:00<?, ?it/s]/tmp/ipykernel_198949/1928987733.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets = [{k: torch.tensor(v).to(device) for k, v in t.items()} for t in targets]\n"
     ]
    }
   ],
   "source": [
    "train_img_folder = \"./building_structures.v1i.coco/train/images\"\n",
    "train_ann_file = \"./building_structures.v1i.coco/train/_annotations.coco.json\"\n",
    "val_img_folder = \"./building_structures.v1i.coco/valid/images\"\n",
    "val_ann_file = \"./building_structures.v1i.coco/valid/_annotations.coco.json\"\n",
    "\n",
    "main(train_img_folder, train_ann_file, val_img_folder, val_ann_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
